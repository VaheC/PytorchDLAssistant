{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 5) (1000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Setting the data for testing\n",
    "\n",
    "np.random.seed(42)\n",
    "X = np.random.randn(1000, 5)\n",
    "\n",
    "a = np.array([0.2, 0.1, 0.4, -0.7, 0.03]).reshape(-1, 1)\n",
    "b = -0.9\n",
    "y = b + X @ a\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data_config/data_prep.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile data_config/data_prep.py\n",
    "\n",
    "np.random.seed(42)\n",
    "X = np.random.randn(1000, 5)\n",
    "\n",
    "a = np.array([0.2, 0.1, 0.4, -0.7, 0.03]).reshape(-1, 1)\n",
    "b = -0.9\n",
    "y = b + X @ a\n",
    "\n",
    "X_tensor = torch.as_tensor(X).float()\n",
    "y_tensor = torch.as_tensor(y).float()\n",
    "\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "\n",
    "train_size = int(X.shape[0] * 0.8)\n",
    "valid_size = X.shape[0] - train_size\n",
    "\n",
    "train_data, valid_data = random_split(dataset, [train_size, valid_size])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_data,\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    dataset=valid_data,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-c01c3be7395062ec\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-c01c3be7395062ec\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing model_config/model_setting.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_config/model_setting.py\n",
    "\n",
    "def create_train_step_fn(model, loss_fn, optimizer):\n",
    "    def output_train_step_loss(X, y):\n",
    "        model.train()\n",
    "        y_hat = model(X)\n",
    "        loss = loss_fn(y_hat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        return loss.item()\n",
    "    return output_train_step_loss\n",
    "\n",
    "def create_valid_step_fn(model, loss_fn):\n",
    "    def output_valid_step_loss(X, y):\n",
    "        model.eval()\n",
    "        y_hat = model(X)\n",
    "        loss = loss_fn(y_hat, y)\n",
    "        return loss.item()\n",
    "    return output_valid_step_loss\n",
    "\n",
    "def get_mini_batch_loss(device, data_loader, step_fn):\n",
    "    mini_batch_losses = []\n",
    "    for X_batch, y_batch in data_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        batch_loss = step_fn(X_batch, y_batch)\n",
    "        mini_batch_losses.append(batch_loss)\n",
    "    \n",
    "    return np.mean(mini_batch_losses)\n",
    "\n",
    "lr = 0.01\n",
    "\n",
    "torch.manual_seed(13)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = nn.Sequential(nn.Linear(5, 1)).to(device)\n",
    "\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "train_step_fn = create_train_step_fn(model, loss_fn, optimizer)\n",
    "valid_step_fn = create_valid_step_fn(model, loss_fn)\n",
    "\n",
    "tensorboard_writer = SummaryWriter('summary/simple_linear_reg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing model/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model/train.py\n",
    "\n",
    "n_epochs = 100\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss = get_mini_batch_loss(device=device, data_loader=train_loader, step_fn=train_step_fn)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        valid_loss = get_mini_batch_loss(device=device, data_loader=valid_loader, step_fn=valid_step_fn)\n",
    "        valid_losses.append(valid_loss)\n",
    "\n",
    "    tensorboard_writer.add_scalars(\n",
    "        main_tag = 'losses',\n",
    "        tag_scalar_dict = {\n",
    "            'train': train_loss,\n",
    "            'validation': valid_loss\n",
    "        },\n",
    "        global_step = epoch\n",
    "    )\n",
    "\n",
    "tensorboard_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i data_config/data_prep.py\n",
    "%run -i model_config/model_setting.py\n",
    "%run -i model/train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight',\n",
       "              tensor([[ 0.2000,  0.1000,  0.4000, -0.7000,  0.0300]], device='cuda:0')),\n",
       "             ('0.bias', tensor([-0.9000], device='cuda:0'))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
